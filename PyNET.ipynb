{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyNET Architecture for Bokeh Effect Simulation","metadata":{"id":"uPTAUlx9vnlb"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"rMwqdLxEvsJb","outputId":"f91a04cd-ccd3-453f-8fc4-3c55461d74c2","execution":{"iopub.status.busy":"2023-01-26T19:23:37.215673Z","iopub.execute_input":"2023-01-26T19:23:37.216337Z","iopub.status.idle":"2023-01-26T19:23:37.223237Z","shell.execute_reply.started":"2023-01-26T19:23:37.216164Z","shell.execute_reply":"2023-01-26T19:23:37.221941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !conda install -c conda-forge gdown\n# !pip install -U tensorflow==2.9.1","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:23:37.226792Z","iopub.execute_input":"2023-01-26T19:23:37.227170Z","iopub.status.idle":"2023-01-26T19:23:37.234207Z","shell.execute_reply.started":"2023-01-26T19:23:37.227113Z","shell.execute_reply":"2023-01-26T19:23:37.233199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !unzip -q '/content/drive/MyDrive/Training.zip'","metadata":{"id":"CL9U1cTOv176","execution":{"iopub.status.busy":"2023-01-26T19:23:37.236033Z","iopub.execute_input":"2023-01-26T19:23:37.236557Z","iopub.status.idle":"2023-01-26T19:23:37.241753Z","shell.execute_reply.started":"2023-01-26T19:23:37.236521Z","shell.execute_reply":"2023-01-26T19:23:37.240590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_DIR='/kaggle/working'\nSAVED_MODEL_FILE='/kaggle/input/pynetweights/pynet.h5'","metadata":{"execution":{"iopub.status.busy":"2023-01-27T10:10:34.549334Z","iopub.execute_input":"2023-01-27T10:10:34.549689Z","iopub.status.idle":"2023-01-27T10:10:34.554391Z","shell.execute_reply.started":"2023-01-27T10:10:34.549660Z","shell.execute_reply":"2023-01-27T10:10:34.553242Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as tfl\nimport numpy as np\nfrom tensorflow.keras.initializers import truncated_normal, Constant","metadata":{"id":"OzmbMCeivnle","execution":{"iopub.status.busy":"2023-01-27T10:08:25.854757Z","iopub.execute_input":"2023-01-27T10:08:25.855116Z","iopub.status.idle":"2023-01-27T10:08:31.201961Z","shell.execute_reply.started":"2023-01-27T10:08:25.855083Z","shell.execute_reply":"2023-01-27T10:08:31.200677Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"gpu = tf.config.list_physical_devices('GPU')[0]\ntf.config.experimental.set_memory_growth(gpu, True)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T10:08:31.207100Z","iopub.execute_input":"2023-01-27T10:08:31.207763Z","iopub.status.idle":"2023-01-27T10:08:31.397308Z","shell.execute_reply.started":"2023-01-27T10:08:31.207721Z","shell.execute_reply":"2023-01-27T10:08:31.392656Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2023-01-27 10:08:31.281326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:31.382987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:31.383824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","output_type":"stream"}]},{"cell_type":"code","source":"def stack(x, y):\n    return tf.concat([x, y], axis= 3)","metadata":{"id":"ZNIVw-gSvnlf","execution":{"iopub.status.busy":"2023-01-27T10:08:31.398914Z","iopub.execute_input":"2023-01-27T10:08:31.399857Z","iopub.status.idle":"2023-01-27T10:08:31.412705Z","shell.execute_reply.started":"2023-01-27T10:08:31.399814Z","shell.execute_reply":"2023-01-27T10:08:31.411528Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def max_pool(x, n):\n    pooling = tfl.MaxPool2D(pool_size=(n, n), strides = (n, n), padding='valid')\n    return pooling(x)","metadata":{"id":"YiTEHN01vnlf","execution":{"iopub.status.busy":"2023-01-27T10:08:31.415954Z","iopub.execute_input":"2023-01-27T10:08:31.417135Z","iopub.status.idle":"2023-01-27T10:08:31.422722Z","shell.execute_reply.started":"2023-01-27T10:08:31.417107Z","shell.execute_reply":"2023-01-27T10:08:31.421781Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def _instance_norm(net):\n\n    batch, rows, cols, channels = [i for i in net.get_shape().as_list()]\n    var_shape = [channels]\n\n    mu, sigma_sq = tf.nn.moments(net, [1,2], keep_dims=True)\n    shift = tf.Variable(tf.zeros(var_shape))\n    scale = tf.Variable(tf.ones(var_shape))\n\n    epsilon = 1e-3\n    normalized = (net-mu)/(sigma_sq + epsilon)**(.5)\n\n    return scale * normalized + shift","metadata":{"id":"jpqNICtZvnlg","execution":{"iopub.status.busy":"2023-01-27T10:08:31.424039Z","iopub.execute_input":"2023-01-27T10:08:31.424854Z","iopub.status.idle":"2023-01-27T10:08:31.432751Z","shell.execute_reply.started":"2023-01-27T10:08:31.424814Z","shell.execute_reply":"2023-01-27T10:08:31.431392Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def _conv_init_vars(net, out_channels, filter_size, transpose=False):\n\n    _, rows, cols, in_channels = [i for i in net.get_shape()]\n\n    if not transpose:\n        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n    else:\n        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n\n    weights_init = tf.Variable(tf.compat.v1.truncated_normal(weights_shape, stddev=0.01, seed=1), dtype=tf.float32)\n    return weights_init","metadata":{"id":"hZQnKbaWvnlg","execution":{"iopub.status.busy":"2023-01-27T10:08:31.434521Z","iopub.execute_input":"2023-01-27T10:08:31.435544Z","iopub.status.idle":"2023-01-27T10:08:31.442704Z","shell.execute_reply.started":"2023-01-27T10:08:31.435496Z","shell.execute_reply":"2023-01-27T10:08:31.441646Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"id":"xVAaUYFBvnlg","outputId":"622c1a0f-5653-49bc-fbff-a79c4329a501","execution":{"iopub.status.busy":"2023-01-27T10:08:31.444408Z","iopub.execute_input":"2023-01-27T10:08:31.444839Z","iopub.status.idle":"2023-01-27T10:08:31.457333Z","shell.execute_reply.started":"2023-01-27T10:08:31.444799Z","shell.execute_reply":"2023-01-27T10:08:31.456279Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'2.6.4'"},"metadata":{}}]},{"cell_type":"code","source":"data = tf.constant(np.arange(10).reshape(5, 2) * 10, dtype=tf.float32)\nprint(data)","metadata":{"id":"jRJ7pLRWvnlh","outputId":"21e56037-99fd-4ade-fc7b-906055b9c407","execution":{"iopub.status.busy":"2023-01-27T10:08:31.458803Z","iopub.execute_input":"2023-01-27T10:08:31.459283Z","iopub.status.idle":"2023-01-27T10:08:33.799898Z","shell.execute_reply.started":"2023-01-27T10:08:31.459247Z","shell.execute_reply":"2023-01-27T10:08:33.798910Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[ 0. 10.]\n [20. 30.]\n [40. 50.]\n [60. 70.]\n [80. 90.]], shape=(5, 2), dtype=float32)\n","output_type":"stream"},{"name":"stderr","text":"2023-01-27 10:08:31.466503: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-27 10:08:31.467012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:31.468021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:31.468778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:33.773681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:33.774640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:33.775366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 10:08:33.776064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"layer = tf.keras.layers.LayerNormalization(axis=[0, 1])\noutput = layer(data)\noutput","metadata":{"id":"s7eXIZoXvnlh","outputId":"4d65df5b-f956-4351-9bf5-c1a85c5725d9","execution":{"iopub.status.busy":"2023-01-27T10:08:33.803598Z","iopub.execute_input":"2023-01-27T10:08:33.804677Z","iopub.status.idle":"2023-01-27T10:08:34.808708Z","shell.execute_reply.started":"2023-01-27T10:08:33.804630Z","shell.execute_reply":"2023-01-27T10:08:34.807603Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2023-01-27 10:08:34.660455: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\narray([[-1.5666981 , -1.2185429 ],\n       [-0.8703878 , -0.5222327 ],\n       [-0.17407757,  0.17407756],\n       [ 0.52223265,  0.8703878 ],\n       [ 1.2185429 ,  1.5666981 ]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"def _conv_layer(net, num_filters, filter_size, strides, relu=True, instance_norm=False, padding='SAME'):\n\n    \"\"\"weights_init = _conv_init_vars(net, num_filters, filter_size)\n    strides_shape = [1, strides, strides, 1]\n    bias = tf.Variable(tf.constant(0.01, shape=[num_filters]))\"\"\"\n\n    #net = tf.nn.conv2d(net, weights_init, strides_shape, padding=padding) + bias\n    layer = tfl.Conv2D(num_filters, kernel_size = filter_size, strides = strides, padding = padding, kernel_initializer = truncated_normal(stddev = 0.01), bias_initializer = Constant(0.01))\n    conv = layer(net)\n    if instance_norm:\n        #conv = _instance_norm(conv)\n        conv = tfl.LayerNormalization(axis = [1, 2])(conv)\n\n    if relu:\n        conv = tfl.LeakyReLU(alpha = 0.2)(conv)\n\n    return conv","metadata":{"id":"_QSUftzEvnli","execution":{"iopub.status.busy":"2023-01-27T10:08:34.810381Z","iopub.execute_input":"2023-01-27T10:08:34.810760Z","iopub.status.idle":"2023-01-27T10:08:34.818394Z","shell.execute_reply.started":"2023-01-27T10:08:34.810724Z","shell.execute_reply":"2023-01-27T10:08:34.817283Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\"\"\"input = tf.Variable(tf.constant(np.random.normal(size = (2, 5, 5, 3))))\na = tfl.Conv2DTranspose(5, kernel_size = 3, strides = 1, padding = 'SAME')(input)\nb = tf.nn.conv2d_transpose(input, )\"\"\"","metadata":{"id":"Zj3jHN6Bvnli","outputId":"8f314084-a75c-4f80-9ef1-0ad7f8e48807","execution":{"iopub.status.busy":"2023-01-27T10:08:34.820365Z","iopub.execute_input":"2023-01-27T10:08:34.820765Z","iopub.status.idle":"2023-01-27T10:08:34.832213Z","shell.execute_reply.started":"2023-01-27T10:08:34.820730Z","shell.execute_reply":"2023-01-27T10:08:34.831215Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"input = tf.Variable(tf.constant(np.random.normal(size = (2, 5, 5, 3))))\\na = tfl.Conv2DTranspose(5, kernel_size = 3, strides = 1, padding = 'SAME')(input)\\nb = tf.nn.conv2d_transpose(input, )\""},"metadata":{}}]},{"cell_type":"code","source":"def _conv_tranpose_layer(net, num_filters, filter_size, strides):\n    weights_init = _conv_init_vars(net, num_filters, filter_size, transpose=True)\n\n    net_shape = tf.shape(net)\n    tf_shape = tf.stack([net_shape[0], net_shape[1] * strides, net_shape[2] * strides, num_filters])\n\n    strides_shape = [1, strides, strides, 1]\n    #net = tf.nn.conv2d_transpose(net, weights_init, tf_shape, strides_shape, padding='SAME')\n    transpose_layer = tfl.Conv2DTranspose(num_filters, kernel_size = filter_size, strides = strides, padding = 'SAME')\n    conv = transpose_layer(net)\n    conv = tfl.LeakyReLU(alpha=0.2)(conv)\n\n    return conv","metadata":{"id":"2z3tlxiFvnli","execution":{"iopub.status.busy":"2023-01-27T10:08:34.833790Z","iopub.execute_input":"2023-01-27T10:08:34.834390Z","iopub.status.idle":"2023-01-27T10:08:34.843293Z","shell.execute_reply.started":"2023-01-27T10:08:34.834350Z","shell.execute_reply":"2023-01-27T10:08:34.842242Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def _conv_multi_block(input, max_size, num_maps, instance_norm):\n    conv_3a = _conv_layer(input, num_maps, 3, 1, relu=True, instance_norm=instance_norm)\n    conv_3b = _conv_layer(conv_3a, num_maps, 3, 1, relu=True, instance_norm=instance_norm)\n\n    output_tensor = conv_3b\n\n    if max_size >= 5:\n\n        conv_5a = _conv_layer(input, num_maps, 5, 1, relu=True, instance_norm=instance_norm)\n        conv_5b = _conv_layer(conv_5a, num_maps, 5, 1, relu=True, instance_norm=instance_norm)\n\n        output_tensor = stack(output_tensor, conv_5b)\n\n    if max_size >= 7:\n\n        conv_7a = _conv_layer(input, num_maps, 7, 1, relu=True, instance_norm=instance_norm)\n        conv_7b = _conv_layer(conv_7a, num_maps, 7, 1, relu=True, instance_norm=instance_norm)\n\n        output_tensor = stack(output_tensor, conv_7b)\n\n    if max_size >= 9:\n\n        conv_9a = _conv_layer(input, num_maps, 9, 1, relu=True, instance_norm=instance_norm)\n        conv_9b = _conv_layer(conv_9a, num_maps, 9, 1, relu=True, instance_norm=instance_norm)\n\n        output_tensor = stack(output_tensor, conv_9b)\n\n    return output_tensor","metadata":{"id":"jdsjCzRFvnlj","execution":{"iopub.status.busy":"2023-01-27T10:08:34.846400Z","iopub.execute_input":"2023-01-27T10:08:34.846752Z","iopub.status.idle":"2023-01-27T10:08:34.856135Z","shell.execute_reply.started":"2023-01-27T10:08:34.846716Z","shell.execute_reply":"2023-01-27T10:08:34.854967Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def PyNET(input, instance_norm = True, instance_norm_level_1 = False):\n    \"\"\"PyNET Architecture\"\"\"\n    \"\"\"Space to depth layer\"\"\"\n    space_to_depth_layer = tfl.Lambda(lambda x : tf.nn.space_to_depth(x, 2))\n    depth = space_to_depth_layer(input)\n\n    # Downsampling layers\n\n    conv_l1_d1 = _conv_multi_block(depth, 3, num_maps=32, instance_norm=False)     # 256 -> 256\n    pool1 = max_pool(conv_l1_d1, 2)                                                         # 256 -> 128\n\n    conv_l2_d1 = _conv_multi_block(pool1, 3, num_maps=64, instance_norm=instance_norm)      # 128 -> 128\n    pool2 = max_pool(conv_l2_d1, 2)                                                         # 128 -> 64\n\n    conv_l3_d1 = _conv_multi_block(pool2, 3, num_maps=128, instance_norm=instance_norm)     # 64 -> 64\n    pool3 = max_pool(conv_l3_d1, 2)                                                         # 64 -> 32\n\n    conv_l4_d1 = _conv_multi_block(pool3, 3, num_maps=256, instance_norm=instance_norm)     # 32 -> 32\n    pool4 = max_pool(conv_l4_d1, 2)                                                         # 32 -> 16\n\n    # -----------------------------------------\n    # Processing: Level 5,  Input size: 16 x 16\n\n    conv_l5_d1 = _conv_multi_block(pool4, 3, num_maps=512, instance_norm=instance_norm)\n    conv_l5_d2 = _conv_multi_block(conv_l5_d1, 3, num_maps=512, instance_norm=instance_norm) + conv_l5_d1\n    conv_l5_d3 = _conv_multi_block(conv_l5_d2, 3, num_maps=512, instance_norm=instance_norm) + conv_l5_d2\n    conv_l5_d4 = _conv_multi_block(conv_l5_d3, 3, num_maps=512, instance_norm=instance_norm)\n\n    conv_t4a = _conv_tranpose_layer(conv_l5_d4, 256, 3, 2)      # 16 -> 32\n    conv_t4b = _conv_tranpose_layer(conv_l5_d4, 256, 3, 2)      # 16 -> 32\n\n    # -> Output: Level 5\n\n    conv_l5_out = _conv_layer(conv_l5_d4, 3, 3, 1, relu=False, instance_norm=False)\n    output_l5 = tf.nn.tanh(conv_l5_out) * 0.58 + 0.5\n\n    # -----------------------------------------\n    # Processing: Level 4,  Input size: 32 x 32\n\n    conv_l4_d2 = stack(conv_l4_d1, conv_t4a)\n    conv_l4_d3 = _conv_multi_block(conv_l4_d2, 3, num_maps=256, instance_norm=instance_norm)\n    conv_l4_d4 = _conv_multi_block(conv_l4_d3, 3, num_maps=256, instance_norm=instance_norm) + conv_l4_d3\n    conv_l4_d5 = _conv_multi_block(conv_l4_d4, 3, num_maps=256, instance_norm=instance_norm) + conv_l4_d4\n    conv_l4_d6 = stack(_conv_multi_block(conv_l4_d5, 3, num_maps=256, instance_norm=instance_norm), conv_t4b)\n\n    conv_l4_d7 = _conv_multi_block(conv_l4_d6, 3, num_maps=256, instance_norm=instance_norm)\n\n    conv_t3a = _conv_tranpose_layer(conv_l4_d7, 128, 3, 2)      # 32 -> 64\n    conv_t3b = _conv_tranpose_layer(conv_l4_d7, 128, 3, 2)      # 32 -> 64\n\n    # -> Output: Level 4\n\n    conv_l4_out = _conv_layer(conv_l4_d7, 3, 3, 1, relu=False, instance_norm=False)\n    output_l4 = tf.nn.tanh(conv_l4_out) * 0.58 + 0.5\n\n    # -----------------------------------------\n    # Processing: Level 3,  Input size: 64 x 64\n\n    conv_l3_d2 = stack(conv_l3_d1, conv_t3a)\n    conv_l3_d3 = _conv_multi_block(conv_l3_d2, 5, num_maps=128, instance_norm=instance_norm) + conv_l3_d2\n    conv_l3_d4 = _conv_multi_block(conv_l3_d3, 5, num_maps=128, instance_norm=instance_norm) + conv_l3_d3\n    conv_l3_d5 = _conv_multi_block(conv_l3_d4, 5, num_maps=128, instance_norm=instance_norm) + conv_l3_d4\n    conv_l3_d6 = stack(_conv_multi_block(conv_l3_d5, 5, num_maps=128, instance_norm=instance_norm), conv_l3_d1)\n    conv_l3_d7 = stack(conv_l3_d6, conv_t3b)\n\n    conv_l3_d8 = _conv_multi_block(conv_l3_d7, 3, num_maps=128, instance_norm=instance_norm)\n\n    conv_t2a = _conv_tranpose_layer(conv_l3_d8, 64, 3, 2)       # 64 -> 128\n    conv_t2b = _conv_tranpose_layer(conv_l3_d8, 64, 3, 2)       # 64 -> 128\n\n    # -> Output: Level 3\n\n    conv_l3_out = _conv_layer(conv_l3_d8, 3, 3, 1, relu=False, instance_norm=False)\n    output_l3 = tf.nn.tanh(conv_l3_out) * 0.58 + 0.5\n\n    # -------------------------------------------\n    # Processing: Level 2,  Input size: 128 x 128\n\n    conv_l2_d2 = stack(conv_l2_d1, conv_t2a)\n    conv_l2_d3 = stack(_conv_multi_block(conv_l2_d2, 5, num_maps=64, instance_norm=instance_norm), conv_l2_d1)\n\n    conv_l2_d4 = _conv_multi_block(conv_l2_d3, 7, num_maps=64, instance_norm=instance_norm) + conv_l2_d3\n    conv_l2_d5 = _conv_multi_block(conv_l2_d4, 7, num_maps=64, instance_norm=instance_norm) + conv_l2_d4\n    conv_l2_d6 = _conv_multi_block(conv_l2_d5, 7, num_maps=64, instance_norm=instance_norm) + conv_l2_d5\n    conv_l2_d7 = stack(_conv_multi_block(conv_l2_d6, 7, num_maps=64, instance_norm=instance_norm), conv_l2_d1)\n\n    conv_l2_d8 = stack(_conv_multi_block(conv_l2_d7, 5, num_maps=64, instance_norm=instance_norm), conv_t2b)\n    conv_l2_d9 = _conv_multi_block(conv_l2_d8, 3, num_maps=64, instance_norm=instance_norm)\n\n    conv_t1a = _conv_tranpose_layer(conv_l2_d9, 32, 3, 2)       # 128 -> 256\n    conv_t1b = _conv_tranpose_layer(conv_l2_d9, 32, 3, 2)       # 128 -> 256\n\n    # -> Output: Level 2\n\n    conv_l2_out = _conv_layer(conv_l2_d9, 3, 3, 1, relu=False, instance_norm=False)\n    output_l2 = tf.nn.tanh(conv_l2_out) * 0.58 + 0.5\n\n    # -------------------------------------------\n    # Processing: Level 1,  Input size: 256 x 256\n\n    conv_l1_d2 = stack(conv_l1_d1, conv_t1a)\n    conv_l1_d3 = stack(_conv_multi_block(conv_l1_d2, 5, num_maps=32, instance_norm=False), conv_l1_d1)\n\n    conv_l1_d4 = _conv_multi_block(conv_l1_d3, 7, num_maps=32, instance_norm=False)\n\n    conv_l1_d5 = _conv_multi_block(conv_l1_d4, 9, num_maps=32, instance_norm=instance_norm_level_1)\n    conv_l1_d6 = _conv_multi_block(conv_l1_d5, 9, num_maps=32, instance_norm=instance_norm_level_1) + conv_l1_d5\n    conv_l1_d7 = _conv_multi_block(conv_l1_d6, 9, num_maps=32, instance_norm=instance_norm_level_1) + conv_l1_d6\n    conv_l1_d8 = _conv_multi_block(conv_l1_d7, 9, num_maps=32, instance_norm=instance_norm_level_1) + conv_l1_d7\n\n    conv_l1_d9 = stack(_conv_multi_block(conv_l1_d8, 7, num_maps=32, instance_norm=False), conv_l1_d1)\n\n    conv_l1_d10 = stack(_conv_multi_block(conv_l1_d9, 5, num_maps=32, instance_norm=False), conv_t1b)\n    conv_l1_d11 = stack(conv_l1_d10, conv_l1_d1)\n\n    conv_l1_d12 = _conv_multi_block(conv_l1_d11, 3, num_maps=32, instance_norm=False)\n\n    # -> Output: Level 1\n\n    conv_l1_out = _conv_layer(conv_l1_d12, 3, 3, 1, relu=False, instance_norm=False)\n    output_l1 = tf.nn.tanh(conv_l1_out) * 0.58 + 0.5\n\n    # ----------------------------------------------------------\n    # Processing: Level 0 (x2 upscaling),  Input size: 256 x 256\n\n    conv_l0 = _conv_tranpose_layer(conv_l1_d12, 8, 3, 2)        # 256 -> 512\n    conv_l0_out = _conv_layer(conv_l0, 3, 3, 1, relu=False, instance_norm=False)\n    output_l0 = tf.nn.tanh(conv_l0_out) * 0.58 + 0.5\n\n    # ----------------------------------------------------------\n    # Processing: Level Up (x4 upscaling),  Input size: 512 x 512\n\n    conv_l_up = _conv_tranpose_layer(conv_l0_out, 3, 3, 2)  # 512 -> 1024\n    conv_l_up_out = _conv_layer(conv_l_up, 3, 3, 1, relu=False, instance_norm=False)\n\n    output_l_up = tf.nn.tanh(conv_l_up_out) * 0.58 + 0.5\n\n    return output_l_up\n","metadata":{"id":"ggz2P2HOvnlj","execution":{"iopub.status.busy":"2023-01-27T10:08:35.592724Z","iopub.execute_input":"2023-01-27T10:08:35.593931Z","iopub.status.idle":"2023-01-27T10:08:35.620436Z","shell.execute_reply.started":"2023-01-27T10:08:35.593894Z","shell.execute_reply":"2023-01-27T10:08:35.619342Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\ninput = tf.keras.Input(shape = (512, 512, 3, ))\nmodel  = tf.keras.Model(inputs = input, outputs = PyNET(input))","metadata":{"id":"P9Cs-vXnvnlk","execution":{"iopub.status.busy":"2023-01-27T10:12:41.970402Z","iopub.execute_input":"2023-01-27T10:12:41.971455Z","iopub.status.idle":"2023-01-27T10:12:44.857030Z","shell.execute_reply.started":"2023-01-27T10:12:41.971408Z","shell.execute_reply":"2023-01-27T10:12:44.856049Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Loading and Preprocessing Data","metadata":{"id":"nhRl0-kvvnlk"}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n# Autotune for fetching and parallel processing tasks\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"id":"vKgg_Mqvvnlk","execution":{"iopub.status.busy":"2023-01-27T10:12:47.475718Z","iopub.execute_input":"2023-01-27T10:12:47.476460Z","iopub.status.idle":"2023-01-27T10:12:47.482407Z","shell.execute_reply.started":"2023-01-27T10:12:47.476424Z","shell.execute_reply":"2023-01-27T10:12:47.481400Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"bokeh_dataset = tf.data.Dataset.list_files('/kaggle/input/bokehdataset/Training/small_bokeh/*.jpg', shuffle = False)\noriginal_dataset = tf.data.Dataset.list_files('/kaggle/input/bokehdataset/Training/small_orig/*.jpg', shuffle = False)\ndataset = tf.data.Dataset.zip((original_dataset, bokeh_dataset))\nimage_count = len(dataset)\nprint(f\"There are {image_count} original-bokeh image pairs in the dataset.\")","metadata":{"id":"wqz9ru2Jvnll","outputId":"d3d8d914-dc1b-446d-c51e-325da9ad0b90","execution":{"iopub.status.busy":"2023-01-27T10:12:48.070645Z","iopub.execute_input":"2023-01-27T10:12:48.073639Z","iopub.status.idle":"2023-01-27T10:12:48.452070Z","shell.execute_reply.started":"2023-01-27T10:12:48.073594Z","shell.execute_reply":"2023-01-27T10:12:48.451091Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"There are 1200 original-bokeh image pairs in the dataset.\n","output_type":"stream"}]},{"cell_type":"code","source":"def decode_img(img):\n    # Convert the compressed string to a 3D uint8 tensor\n    img = tf.io.decode_jpeg(img, channels=3)\n    # Resize the image to the desired size\n    img = tf.image.resize(img, [1024, 1536], method = 'bicubic')\n    return img\n\ndef process_path(original_path, bokeh_path):\n    # Load the raw data from the file as a string\n    bokeh_img = tf.io.read_file(bokeh_path)\n    original_img = tf.io.read_file(original_path)\n    bokeh_img = decode_img(bokeh_img)\n    original_img = decode_img(original_img)\n    return original_img, bokeh_img\n\n# Convert the dataset from filepaths to image tensors\ndataset = dataset.map(process_path, num_parallel_calls=AUTOTUNE)","metadata":{"id":"Wk7ZnXM7vnll","execution":{"iopub.status.busy":"2023-01-27T10:12:48.658338Z","iopub.execute_input":"2023-01-27T10:12:48.659247Z","iopub.status.idle":"2023-01-27T10:12:48.794432Z","shell.execute_reply.started":"2023-01-27T10:12:48.659190Z","shell.execute_reply":"2023-01-27T10:12:48.793092Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Splitting into training and validation datsets\ntrain_dataset = dataset.skip(int(image_count*0.2))\nvalidation_dataset = dataset.take(int(image_count*0.2))\n\nprint(f\"Training Dataset: {len(train_dataset)} image pairs\")\nprint(f\"Validation Dataset: {len(validation_dataset)} image pairs\")","metadata":{"id":"rh-7Sgi6vnll","outputId":"a209894f-86e4-44d8-dcb2-063233d8317a","execution":{"iopub.status.busy":"2023-01-27T10:12:50.210568Z","iopub.execute_input":"2023-01-27T10:12:50.210957Z","iopub.status.idle":"2023-01-27T10:12:50.219568Z","shell.execute_reply.started":"2023-01-27T10:12:50.210922Z","shell.execute_reply":"2023-01-27T10:12:50.218580Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Training Dataset: 960 image pairs\nValidation Dataset: 240 image pairs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We need random square crops of the image for input and output.","metadata":{"id":"ETliv_6Zvnll"}},{"cell_type":"code","source":"def random_crops(original, bokeh):\n    _, h, w, c = original.get_shape().as_list()\n    \"\"\"print(h, w)\n    print(batch.get_shape().as_list())\n    print(type(batch))\"\"\"\n    original = original/255.0\n    bokeh = bokeh/255.0\n    stacked = tf.concat((original, bokeh), axis = -1)\n    stacked = tf.image.random_crop(stacked, [BATCH_SIZE, 1024, 1024, 6])\n    original, bokeh = tf.split(stacked, num_or_size_splits=2, axis = -1)\n    original = tf.image.resize(original, size = [512, 512], method = 'bicubic')\n    return original, bokeh","metadata":{"id":"-3wKfEnuvnll","execution":{"iopub.status.busy":"2023-01-27T10:12:52.072693Z","iopub.execute_input":"2023-01-27T10:12:52.073772Z","iopub.status.idle":"2023-01-27T10:12:52.080986Z","shell.execute_reply.started":"2023-01-27T10:12:52.073728Z","shell.execute_reply":"2023-01-27T10:12:52.079872Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Resize and crop the dataset for training\ndef resize_for_training(train_dataset):\n    train_dataset = train_dataset.map(random_crops, num_parallel_calls=AUTOTUNE)\n    return train_dataset","metadata":{"id":"aT8i1KE8vnll","execution":{"iopub.status.busy":"2023-01-27T10:12:52.211798Z","iopub.execute_input":"2023-01-27T10:12:52.212101Z","iopub.status.idle":"2023-01-27T10:12:52.217538Z","shell.execute_reply.started":"2023-01-27T10:12:52.212074Z","shell.execute_reply":"2023-01-27T10:12:52.216588Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Improve performance of the data input pipeline\ndef configure_for_performance(dataset):\n#     dataset = dataset.shuffle(buffer_size=16)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(1)\n    return dataset","metadata":{"id":"QV_niD1svnlm","execution":{"iopub.status.busy":"2023-01-27T10:12:52.868491Z","iopub.execute_input":"2023-01-27T10:12:52.868858Z","iopub.status.idle":"2023-01-27T10:12:52.873913Z","shell.execute_reply.started":"2023-01-27T10:12:52.868819Z","shell.execute_reply":"2023-01-27T10:12:52.872681Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_dataset = configure_for_performance(train_dataset)\nvalidation_dataset = configure_for_performance(validation_dataset)","metadata":{"id":"-niYpHvsvnlm","execution":{"iopub.status.busy":"2023-01-27T10:12:54.858461Z","iopub.execute_input":"2023-01-27T10:12:54.859597Z","iopub.status.idle":"2023-01-27T10:12:54.875658Z","shell.execute_reply.started":"2023-01-27T10:12:54.859552Z","shell.execute_reply":"2023-01-27T10:12:54.873564Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"type(train_dataset), len(train_dataset)","metadata":{"id":"qu9RfiAU7zMQ","outputId":"d7b74cdd-5e2b-441a-88cc-023d644b6e3a","execution":{"iopub.status.busy":"2023-01-27T10:12:55.004489Z","iopub.execute_input":"2023-01-27T10:12:55.004860Z","iopub.status.idle":"2023-01-27T10:12:55.012978Z","shell.execute_reply.started":"2023-01-27T10:12:55.004827Z","shell.execute_reply":"2023-01-27T10:12:55.011800Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(tensorflow.python.data.ops.dataset_ops.PrefetchDataset, 240)"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = resize_for_training(train_dataset)","metadata":{"id":"N90witsOvnlm","execution":{"iopub.status.busy":"2023-01-27T10:12:55.134082Z","iopub.execute_input":"2023-01-27T10:12:55.134450Z","iopub.status.idle":"2023-01-27T10:12:55.251803Z","shell.execute_reply.started":"2023-01-27T10:12:55.134414Z","shell.execute_reply":"2023-01-27T10:12:55.250893Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"type(train_dataset)","metadata":{"id":"wbGQoyyn74dz","outputId":"75dba6da-58ab-4df8-ef47-ddf43c3a69c3","execution":{"iopub.status.busy":"2023-01-27T10:12:56.191141Z","iopub.execute_input":"2023-01-27T10:12:56.191912Z","iopub.status.idle":"2023-01-27T10:12:56.201374Z","shell.execute_reply.started":"2023-01-27T10:12:56.191878Z","shell.execute_reply":"2023-01-27T10:12:56.200268Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"tensorflow.python.data.ops.dataset_ops.ParallelMapDataset"},"metadata":{}}]},{"cell_type":"markdown","source":"# Custom Loss Function (For Level 1)","metadata":{"id":"Yx6eFiSrvnlm"}},{"cell_type":"markdown","source":"## VGG Network","metadata":{"id":"S5-YPsxOvnlm"}},{"cell_type":"code","source":"# !unzip '/content/drive/MyDrive/VGG.zip'","metadata":{"id":"-3-t_pFr2X35","outputId":"fe7c23cc-479e-4976-f340-62e084ec4279","execution":{"iopub.status.busy":"2023-01-27T10:12:57.818148Z","iopub.execute_input":"2023-01-27T10:12:57.818545Z","iopub.status.idle":"2023-01-27T10:12:57.823090Z","shell.execute_reply.started":"2023-01-27T10:12:57.818513Z","shell.execute_reply":"2023-01-27T10:12:57.822068Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from scipy.io import loadmat\nfrom tensorflow.keras.losses import MeanSquaredError\nvgg_matlab = loadmat('/kaggle/input/bokehdataset/VGG/VGG/imagenet-vgg-verydeep-19.mat')\nvgg_weights = vgg_matlab['layers'][0]\nlayers = (\n        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n\n        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n\n        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n\n        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n\n        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n        'relu5_3', 'conv5_4', 'relu5_4'\n    )","metadata":{"id":"EdAIb_Jtvnlm","execution":{"iopub.status.busy":"2023-01-27T10:12:57.968423Z","iopub.execute_input":"2023-01-27T10:12:57.969041Z","iopub.status.idle":"2023-01-27T10:13:02.727618Z","shell.execute_reply.started":"2023-01-27T10:12:57.968998Z","shell.execute_reply":"2023-01-27T10:13:02.726572Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"IMAGE_MEAN = np.array([123.68,  116.779,  103.939])\ndef vgg_conv_layer(input, weights, bias):\n    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1), padding='SAME')\n    return tf.nn.bias_add(conv, bias)\n\ndef vgg_net(input_image):\n    input_image = input_image - IMAGE_MEAN\n    current = input_image\n    net = current\n    for i, name in enumerate(layers):\n        layer_type = name[:4]\n        if layer_type == 'conv':\n            kernels, bias = vgg_weights[i][0][0][0][0]\n            kernels = np.transpose(kernels, (1, 0, 2, 3))\n            bias = bias.reshape(-1)\n            current = vgg_conv_layer(current, kernels, bias)\n        elif layer_type == 'relu':\n            current = tf.nn.relu(current)\n        elif layer_type == 'pool':\n            current = tf.nn.max_pool(current, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='SAME')\n        net = current\n\n    return net","metadata":{"id":"jLFRiPP5vnlm","execution":{"iopub.status.busy":"2023-01-27T10:13:02.729900Z","iopub.execute_input":"2023-01-27T10:13:02.730628Z","iopub.status.idle":"2023-01-27T10:13:02.740576Z","shell.execute_reply.started":"2023-01-27T10:13:02.730589Z","shell.execute_reply":"2023-01-27T10:13:02.739512Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def Level_1_loss(bokeh, target):\n    # L1_loss\n    # print(f\"shape of bokeh {bokeh.get_shape()}\")\n    # print(f\"shape of target {target.get_shape()}\")\n    l1_loss = tf.abs(tf.subtract(bokeh, target))\n    # SSIM loss\n    SSIM_loss = tf.reduce_mean(tf.image.ssim(bokeh, target, 1.0))\n    # VGG Loss\n    bokeh_image_vgg = vgg_net(bokeh*255)\n    target_vgg = vgg_net(target*255)\n    VGG_loss = MeanSquaredError()(bokeh_image_vgg, target_vgg)\n    return l1_loss + (1 - SSIM_loss) + 0.01*VGG_loss","metadata":{"id":"1Q9tXUWevnlm","execution":{"iopub.status.busy":"2023-01-27T10:13:02.742160Z","iopub.execute_input":"2023-01-27T10:13:02.742628Z","iopub.status.idle":"2023-01-27T10:13:02.753186Z","shell.execute_reply.started":"2023-01-27T10:13:02.742591Z","shell.execute_reply":"2023-01-27T10:13:02.752270Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Model Saving Checkpoints","metadata":{"id":"3aKKLNta22Xi"}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nsave_model = ModelCheckpoint(\n    '/kaggle/working/pynet.h5',\n    monitor = 'loss',\n    save_best_only = True,\n    verbose = 1\n)","metadata":{"id":"Z4rNxyYd2x_a","execution":{"iopub.status.busy":"2023-01-27T10:57:40.595898Z","iopub.execute_input":"2023-01-27T10:57:40.596361Z","iopub.status.idle":"2023-01-27T10:57:40.602416Z","shell.execute_reply.started":"2023-01-27T10:57:40.596315Z","shell.execute_reply":"2023-01-27T10:57:40.601276Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nmodel.compile(\n    optimizer = Adam(1e-4),\n    loss = Level_1_loss,\n    metrics = ['MeanSquaredError']\n)","metadata":{"id":"UOFaAcsZvnlm","execution":{"iopub.status.busy":"2023-01-27T10:13:08.788061Z","iopub.execute_input":"2023-01-27T10:13:08.788754Z","iopub.status.idle":"2023-01-27T10:13:08.810049Z","shell.execute_reply.started":"2023-01-27T10:13:08.788715Z","shell.execute_reply":"2023-01-27T10:13:08.809128Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"id":"VFa8iarN7WB0","outputId":"cce8069c-0c83-4d57-ac31-91c95f959e66","execution":{"iopub.status.busy":"2023-01-27T10:13:10.246222Z","iopub.execute_input":"2023-01-27T10:13:10.246659Z","iopub.status.idle":"2023-01-27T10:13:10.254845Z","shell.execute_reply.started":"2023-01-27T10:13:10.246624Z","shell.execute_reply":"2023-01-27T10:13:10.253880Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"240"},"metadata":{}}]},{"cell_type":"code","source":"# original, bokeh = next(iter(train_dataset))","metadata":{"id":"qsgLa5Zu6qUU","execution":{"iopub.status.busy":"2023-01-27T10:13:11.670107Z","iopub.execute_input":"2023-01-27T10:13:11.670820Z","iopub.status.idle":"2023-01-27T10:13:11.675257Z","shell.execute_reply.started":"2023-01-27T10:13:11.670783Z","shell.execute_reply":"2023-01-27T10:13:11.674261Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\"\"\"import matplotlib.pyplot as plt\nplt.figure(figsize=(10, 10))\nstart = 2\nfor i in range(start, start + 2):\n  ax = plt.subplot(2, 2, 2*(i-start) + 1)\n  plt.imshow(original[i].numpy().astype(\"uint8\"))\n  ax = plt.subplot(2, 2, 2*(i-start) + 2)\n  plt.imshow(bokeh[i].numpy().astype(\"uint8\"))\"\"\"","metadata":{"id":"3oyy1c6D-CPp","outputId":"f757dd1a-19dc-45c5-ebd8-fe717d4acee2","execution":{"iopub.status.busy":"2023-01-27T10:13:12.188863Z","iopub.execute_input":"2023-01-27T10:13:12.191167Z","iopub.status.idle":"2023-01-27T10:13:12.199496Z","shell.execute_reply.started":"2023-01-27T10:13:12.191132Z","shell.execute_reply":"2023-01-27T10:13:12.198378Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'import matplotlib.pyplot as plt\\nplt.figure(figsize=(10, 10))\\nstart = 2\\nfor i in range(start, start + 2):\\n  ax = plt.subplot(2, 2, 2*(i-start) + 1)\\n  plt.imshow(original[i].numpy().astype(\"uint8\"))\\n  ax = plt.subplot(2, 2, 2*(i-start) + 2)\\n  plt.imshow(bokeh[i].numpy().astype(\"uint8\"))'"},"metadata":{}}]},{"cell_type":"code","source":"# config = tf.ConfigProto()\n# config.gpu_options.allow_growth = True\n# sess = tf.Session(config = config)\n# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n# tf.config.experimental.set_memory_growth(physical_devices[0], True)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T10:13:13.215503Z","iopub.execute_input":"2023-01-27T10:13:13.215860Z","iopub.status.idle":"2023-01-27T10:13:13.220384Z","shell.execute_reply.started":"2023-01-27T10:13:13.215829Z","shell.execute_reply":"2023-01-27T10:13:13.219100Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-01-27T10:13:20.929201Z","iopub.execute_input":"2023-01-27T10:13:20.929603Z","iopub.status.idle":"2023-01-27T10:13:21.920149Z","shell.execute_reply.started":"2023-01-27T10:13:20.929571Z","shell.execute_reply":"2023-01-27T10:13:21.918993Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights(SAVED_MODEL_FILE)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T10:13:53.930191Z","iopub.execute_input":"2023-01-27T10:13:53.931292Z","iopub.status.idle":"2023-01-27T10:13:56.721468Z","shell.execute_reply.started":"2023-01-27T10:13:53.931238Z","shell.execute_reply":"2023-01-27T10:13:56.720413Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model.save_weights('./pynet.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-27T10:46:45.755341Z","iopub.execute_input":"2023-01-27T10:46:45.755783Z","iopub.status.idle":"2023-01-27T10:46:46.598400Z","shell.execute_reply.started":"2023-01-27T10:46:45.755747Z","shell.execute_reply":"2023-01-27T10:46:46.597211Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    train_dataset,\n    epochs = 1,\n    callbacks = [save_model]\n)","metadata":{"id":"ybhG2OM4vnln","outputId":"272360c0-d9e2-4a46-dcf3-e296f9d828ee","execution":{"iopub.status.busy":"2023-01-27T11:30:39.795166Z","iopub.execute_input":"2023-01-27T11:30:39.796258Z","iopub.status.idle":"2023-01-27T11:41:01.792479Z","shell.execute_reply.started":"2023-01-27T11:30:39.796194Z","shell.execute_reply":"2023-01-27T11:41:01.791355Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"240/240 [==============================] - 594s 2s/step - loss: 0.3392 - mean_squared_error: 0.0120\n\nEpoch 00001: loss improved from 0.34281 to 0.33924, saving model to /kaggle/working/pynet.h5\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fd1dc5ff150>"},"metadata":{}}]}]}