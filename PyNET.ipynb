{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"9dbf8f4c165eb0b71c72ee397a4a34a0cbf4814bae4fb3ea460f3ccc58581f59"}},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyNET Architecture for Bokeh Effect Simulation","metadata":{"id":"uPTAUlx9vnlb"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMwqdLxEvsJb","outputId":"f91a04cd-ccd3-453f-8fc4-3c55461d74c2","execution":{"iopub.status.busy":"2023-01-26T19:23:37.215673Z","iopub.execute_input":"2023-01-26T19:23:37.216337Z","iopub.status.idle":"2023-01-26T19:23:37.223237Z","shell.execute_reply.started":"2023-01-26T19:23:37.216164Z","shell.execute_reply":"2023-01-26T19:23:37.221941Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !conda install -c conda-forge gdown\n# !pip install -U tensorflow==2.9.1","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:23:37.226792Z","iopub.execute_input":"2023-01-26T19:23:37.227170Z","iopub.status.idle":"2023-01-26T19:23:37.234207Z","shell.execute_reply.started":"2023-01-26T19:23:37.227113Z","shell.execute_reply":"2023-01-26T19:23:37.233199Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !unzip -q '/content/drive/MyDrive/Training.zip'","metadata":{"id":"CL9U1cTOv176","execution":{"iopub.status.busy":"2023-01-26T19:23:37.236033Z","iopub.execute_input":"2023-01-26T19:23:37.236557Z","iopub.status.idle":"2023-01-26T19:23:37.241753Z","shell.execute_reply.started":"2023-01-26T19:23:37.236521Z","shell.execute_reply":"2023-01-26T19:23:37.240590Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as tfl\nimport numpy as np\nfrom tensorflow.keras.initializers import truncated_normal, Constant","metadata":{"id":"OzmbMCeivnle","execution":{"iopub.status.busy":"2023-01-26T19:23:37.243455Z","iopub.execute_input":"2023-01-26T19:23:37.243963Z","iopub.status.idle":"2023-01-26T19:23:39.095084Z","shell.execute_reply.started":"2023-01-26T19:23:37.243929Z","shell.execute_reply":"2023-01-26T19:23:39.093934Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"gpu = tf.config.list_physical_devices('GPU')[0]\ntf.config.experimental.set_memory_growth(gpu, True)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:23:39.098190Z","iopub.execute_input":"2023-01-26T19:23:39.098917Z","iopub.status.idle":"2023-01-26T19:23:39.153903Z","shell.execute_reply.started":"2023-01-26T19:23:39.098876Z","shell.execute_reply":"2023-01-26T19:23:39.152421Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2023-01-26 19:23:39.137553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.147367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.148086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","output_type":"stream"}]},{"cell_type":"code","source":"def stack(x, y):\n    return tf.concat([x, y], axis= 3)","metadata":{"id":"ZNIVw-gSvnlf","execution":{"iopub.status.busy":"2023-01-26T19:23:39.155593Z","iopub.execute_input":"2023-01-26T19:23:39.156289Z","iopub.status.idle":"2023-01-26T19:23:39.163349Z","shell.execute_reply.started":"2023-01-26T19:23:39.156252Z","shell.execute_reply":"2023-01-26T19:23:39.162378Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def max_pool(x, n):\n    pooling = tfl.MaxPool2D(pool_size=(n, n), strides = (n, n), padding='valid')\n    return pooling(x)","metadata":{"id":"YiTEHN01vnlf","execution":{"iopub.status.busy":"2023-01-26T19:23:39.164734Z","iopub.execute_input":"2023-01-26T19:23:39.165332Z","iopub.status.idle":"2023-01-26T19:23:39.172168Z","shell.execute_reply.started":"2023-01-26T19:23:39.165297Z","shell.execute_reply":"2023-01-26T19:23:39.171215Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def _instance_norm(net):\n\n    batch, rows, cols, channels = [i for i in net.get_shape().as_list()]\n    var_shape = [channels]\n\n    mu, sigma_sq = tf.nn.moments(net, [1,2], keep_dims=True)\n    shift = tf.Variable(tf.zeros(var_shape))\n    scale = tf.Variable(tf.ones(var_shape))\n\n    epsilon = 1e-3\n    normalized = (net-mu)/(sigma_sq + epsilon)**(.5)\n\n    return scale * normalized + shift","metadata":{"id":"jpqNICtZvnlg","execution":{"iopub.status.busy":"2023-01-26T19:23:39.173666Z","iopub.execute_input":"2023-01-26T19:23:39.174115Z","iopub.status.idle":"2023-01-26T19:23:39.183370Z","shell.execute_reply.started":"2023-01-26T19:23:39.174080Z","shell.execute_reply":"2023-01-26T19:23:39.182423Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def _conv_init_vars(net, out_channels, filter_size, transpose=False):\n\n    _, rows, cols, in_channels = [i for i in net.get_shape()]\n\n    if not transpose:\n        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n    else:\n        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n\n    weights_init = tf.Variable(tf.compat.v1.truncated_normal(weights_shape, stddev=0.01, seed=1), dtype=tf.float32)\n    return weights_init","metadata":{"id":"hZQnKbaWvnlg","execution":{"iopub.status.busy":"2023-01-26T19:23:39.184985Z","iopub.execute_input":"2023-01-26T19:23:39.185373Z","iopub.status.idle":"2023-01-26T19:23:39.192821Z","shell.execute_reply.started":"2023-01-26T19:23:39.185339Z","shell.execute_reply":"2023-01-26T19:23:39.191735Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xVAaUYFBvnlg","outputId":"622c1a0f-5653-49bc-fbff-a79c4329a501","execution":{"iopub.status.busy":"2023-01-26T19:23:39.195821Z","iopub.execute_input":"2023-01-26T19:23:39.196288Z","iopub.status.idle":"2023-01-26T19:23:39.205740Z","shell.execute_reply.started":"2023-01-26T19:23:39.196253Z","shell.execute_reply":"2023-01-26T19:23:39.204526Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'2.6.4'"},"metadata":{}}]},{"cell_type":"code","source":"data = tf.constant(np.arange(10).reshape(5, 2) * 10, dtype=tf.float32)\nprint(data)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jRJ7pLRWvnlh","outputId":"21e56037-99fd-4ade-fc7b-906055b9c407","execution":{"iopub.status.busy":"2023-01-26T19:23:39.207356Z","iopub.execute_input":"2023-01-26T19:23:39.207943Z","iopub.status.idle":"2023-01-26T19:23:39.888881Z","shell.execute_reply.started":"2023-01-26T19:23:39.207907Z","shell.execute_reply":"2023-01-26T19:23:39.886839Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[ 0. 10.]\n [20. 30.]\n [40. 50.]\n [60. 70.]\n [80. 90.]], shape=(5, 2), dtype=float32)\n","output_type":"stream"},{"name":"stderr","text":"2023-01-26 19:23:39.210887: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-26 19:23:39.211296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.212314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.213289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.876216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.877011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.877715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-26 19:23:39.878312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"layer = tf.keras.layers.LayerNormalization(axis=[0, 1])\noutput = layer(data)\noutput","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7eXIZoXvnlh","outputId":"4d65df5b-f956-4351-9bf5-c1a85c5725d9","execution":{"iopub.status.busy":"2023-01-26T19:23:39.890272Z","iopub.execute_input":"2023-01-26T19:23:39.890681Z","iopub.status.idle":"2023-01-26T19:23:40.232315Z","shell.execute_reply.started":"2023-01-26T19:23:39.890651Z","shell.execute_reply":"2023-01-26T19:23:40.231223Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2023-01-26 19:23:40.189364: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\narray([[-1.5666981 , -1.2185429 ],\n       [-0.8703878 , -0.5222327 ],\n       [-0.17407757,  0.17407756],\n       [ 0.52223265,  0.8703878 ],\n       [ 1.2185429 ,  1.5666981 ]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"def _conv_layer(net, num_filters, filter_size, strides, relu=True, instance_norm=False, padding='SAME'):\n\n    \"\"\"weights_init = _conv_init_vars(net, num_filters, filter_size)\n    strides_shape = [1, strides, strides, 1]\n    bias = tf.Variable(tf.constant(0.01, shape=[num_filters]))\"\"\"\n\n    #net = tf.nn.conv2d(net, weights_init, strides_shape, padding=padding) + bias\n    layer = tfl.Conv2D(num_filters, kernel_size = filter_size, strides = strides, padding = padding, kernel_initializer = truncated_normal(stddev = 0.01), bias_initializer = Constant(0.01))\n    conv = layer(net)\n    if instance_norm:\n        #conv = _instance_norm(conv)\n        conv = tfl.LayerNormalization(axis = [1, 2])(conv)\n\n    if relu:\n        conv = tfl.LeakyReLU(alpha = 0.2)(conv)\n\n    return conv","metadata":{"id":"_QSUftzEvnli","execution":{"iopub.status.busy":"2023-01-26T19:23:40.233772Z","iopub.execute_input":"2023-01-26T19:23:40.234265Z","iopub.status.idle":"2023-01-26T19:23:40.244655Z","shell.execute_reply.started":"2023-01-26T19:23:40.234227Z","shell.execute_reply":"2023-01-26T19:23:40.243625Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\"\"\"input = tf.Variable(tf.constant(np.random.normal(size = (2, 5, 5, 3))))\na = tfl.Conv2DTranspose(5, kernel_size = 3, strides = 1, padding = 'SAME')(input)\nb = tf.nn.conv2d_transpose(input, )\"\"\"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"Zj3jHN6Bvnli","outputId":"8f314084-a75c-4f80-9ef1-0ad7f8e48807","execution":{"iopub.status.busy":"2023-01-26T19:23:40.252337Z","iopub.execute_input":"2023-01-26T19:23:40.252615Z","iopub.status.idle":"2023-01-26T19:23:40.262415Z","shell.execute_reply.started":"2023-01-26T19:23:40.252583Z","shell.execute_reply":"2023-01-26T19:23:40.261410Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"input = tf.Variable(tf.constant(np.random.normal(size = (2, 5, 5, 3))))\\na = tfl.Conv2DTranspose(5, kernel_size = 3, strides = 1, padding = 'SAME')(input)\\nb = tf.nn.conv2d_transpose(input, )\""},"metadata":{}}]},{"cell_type":"code","source":"def _conv_tranpose_layer(net, num_filters, filter_size, strides):\n    weights_init = _conv_init_vars(net, num_filters, filter_size, transpose=True)\n\n    net_shape = tf.shape(net)\n    tf_shape = tf.stack([net_shape[0], net_shape[1] * strides, net_shape[2] * strides, num_filters])\n\n    strides_shape = [1, strides, strides, 1]\n    #net = tf.nn.conv2d_transpose(net, weights_init, tf_shape, strides_shape, padding='SAME')\n    transpose_layer = tfl.Conv2DTranspose(num_filters, kernel_size = filter_size, strides = strides, padding = 'SAME')\n    conv = transpose_layer(net)\n    conv = tfl.LeakyReLU(alpha=0.2)(conv)\n\n    return conv","metadata":{"id":"2z3tlxiFvnli","execution":{"iopub.status.busy":"2023-01-26T19:23:40.265730Z","iopub.execute_input":"2023-01-26T19:23:40.265981Z","iopub.status.idle":"2023-01-26T19:23:40.272969Z","shell.execute_reply.started":"2023-01-26T19:23:40.265958Z","shell.execute_reply":"2023-01-26T19:23:40.271588Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def _conv_multi_block(input, max_size, num_maps, instance_norm):\n    conv_3a = _conv_layer(input, num_maps, 3, 1, relu=True, instance_norm=instance_norm)\n    conv_3b = _conv_layer(conv_3a, num_maps, 3, 1, relu=True, instance_norm=instance_norm)\n\n    output_tensor = conv_3b\n\n    if max_size >= 5:\n\n        conv_5a = _conv_layer(input, num_maps, 5, 1, relu=True, instance_norm=instance_norm)\n        conv_5b = _conv_layer(conv_5a, num_maps, 5, 1, relu=True, instance_norm=instance_norm)\n\n        output_tensor = stack(output_tensor, conv_5b)\n\n    if max_size >= 7:\n\n        conv_7a = _conv_layer(input, num_maps, 7, 1, relu=True, instance_norm=instance_norm)\n        conv_7b = _conv_layer(conv_7a, num_maps, 7, 1, relu=True, instance_norm=instance_norm)\n\n        output_tensor = stack(output_tensor, conv_7b)\n\n    if max_size >= 9:\n\n        conv_9a = _conv_layer(input, num_maps, 9, 1, relu=True, instance_norm=instance_norm)\n        conv_9b = _conv_layer(conv_9a, num_maps, 9, 1, relu=True, instance_norm=instance_norm)\n\n        output_tensor = stack(output_tensor, conv_9b)\n\n    return output_tensor","metadata":{"id":"jdsjCzRFvnlj","execution":{"iopub.status.busy":"2023-01-26T19:23:40.274849Z","iopub.execute_input":"2023-01-26T19:23:40.275408Z","iopub.status.idle":"2023-01-26T19:23:40.285529Z","shell.execute_reply.started":"2023-01-26T19:23:40.275365Z","shell.execute_reply":"2023-01-26T19:23:40.284581Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def PyNET(input, instance_norm = True, instance_norm_level_1 = False):\n    \"\"\"PyNET Architecture\"\"\"\n    \"\"\"Space to depth layer\"\"\"\n    space_to_depth_layer = tfl.Lambda(lambda x : tf.nn.space_to_depth(x, 2))\n    depth = space_to_depth_layer(input)\n\n    # Downsampling layers\n\n    conv_l1_d1 = _conv_multi_block(depth, 3, num_maps=32, instance_norm=False)     # 256 -> 256\n    pool1 = max_pool(conv_l1_d1, 2)                                                         # 256 -> 128\n\n    conv_l2_d1 = _conv_multi_block(pool1, 3, num_maps=64, instance_norm=instance_norm)      # 128 -> 128\n    pool2 = max_pool(conv_l2_d1, 2)                                                         # 128 -> 64\n\n    conv_l3_d1 = _conv_multi_block(pool2, 3, num_maps=128, instance_norm=instance_norm)     # 64 -> 64\n    pool3 = max_pool(conv_l3_d1, 2)                                                         # 64 -> 32\n\n    conv_l4_d1 = _conv_multi_block(pool3, 3, num_maps=256, instance_norm=instance_norm)     # 32 -> 32\n    pool4 = max_pool(conv_l4_d1, 2)                                                         # 32 -> 16\n\n    # -----------------------------------------\n    # Processing: Level 5,  Input size: 16 x 16\n\n    conv_l5_d1 = _conv_multi_block(pool4, 3, num_maps=512, instance_norm=instance_norm)\n    conv_l5_d2 = _conv_multi_block(conv_l5_d1, 3, num_maps=512, instance_norm=instance_norm) + conv_l5_d1\n    conv_l5_d3 = _conv_multi_block(conv_l5_d2, 3, num_maps=512, instance_norm=instance_norm) + conv_l5_d2\n    conv_l5_d4 = _conv_multi_block(conv_l5_d3, 3, num_maps=512, instance_norm=instance_norm)\n\n    conv_t4a = _conv_tranpose_layer(conv_l5_d4, 256, 3, 2)      # 16 -> 32\n    conv_t4b = _conv_tranpose_layer(conv_l5_d4, 256, 3, 2)      # 16 -> 32\n\n    # -> Output: Level 5\n\n    conv_l5_out = _conv_layer(conv_l5_d4, 3, 3, 1, relu=False, instance_norm=False)\n    output_l5 = tf.nn.tanh(conv_l5_out) * 0.58 + 0.5\n\n    # -----------------------------------------\n    # Processing: Level 4,  Input size: 32 x 32\n\n    conv_l4_d2 = stack(conv_l4_d1, conv_t4a)\n    conv_l4_d3 = _conv_multi_block(conv_l4_d2, 3, num_maps=256, instance_norm=instance_norm)\n    conv_l4_d4 = _conv_multi_block(conv_l4_d3, 3, num_maps=256, instance_norm=instance_norm) + conv_l4_d3\n    conv_l4_d5 = _conv_multi_block(conv_l4_d4, 3, num_maps=256, instance_norm=instance_norm) + conv_l4_d4\n    conv_l4_d6 = stack(_conv_multi_block(conv_l4_d5, 3, num_maps=256, instance_norm=instance_norm), conv_t4b)\n\n    conv_l4_d7 = _conv_multi_block(conv_l4_d6, 3, num_maps=256, instance_norm=instance_norm)\n\n    conv_t3a = _conv_tranpose_layer(conv_l4_d7, 128, 3, 2)      # 32 -> 64\n    conv_t3b = _conv_tranpose_layer(conv_l4_d7, 128, 3, 2)      # 32 -> 64\n\n    # -> Output: Level 4\n\n    conv_l4_out = _conv_layer(conv_l4_d7, 3, 3, 1, relu=False, instance_norm=False)\n    output_l4 = tf.nn.tanh(conv_l4_out) * 0.58 + 0.5\n\n    # -----------------------------------------\n    # Processing: Level 3,  Input size: 64 x 64\n\n    conv_l3_d2 = stack(conv_l3_d1, conv_t3a)\n    conv_l3_d3 = _conv_multi_block(conv_l3_d2, 5, num_maps=128, instance_norm=instance_norm) + conv_l3_d2\n    conv_l3_d4 = _conv_multi_block(conv_l3_d3, 5, num_maps=128, instance_norm=instance_norm) + conv_l3_d3\n    conv_l3_d5 = _conv_multi_block(conv_l3_d4, 5, num_maps=128, instance_norm=instance_norm) + conv_l3_d4\n    conv_l3_d6 = stack(_conv_multi_block(conv_l3_d5, 5, num_maps=128, instance_norm=instance_norm), conv_l3_d1)\n    conv_l3_d7 = stack(conv_l3_d6, conv_t3b)\n\n    conv_l3_d8 = _conv_multi_block(conv_l3_d7, 3, num_maps=128, instance_norm=instance_norm)\n\n    conv_t2a = _conv_tranpose_layer(conv_l3_d8, 64, 3, 2)       # 64 -> 128\n    conv_t2b = _conv_tranpose_layer(conv_l3_d8, 64, 3, 2)       # 64 -> 128\n\n    # -> Output: Level 3\n\n    conv_l3_out = _conv_layer(conv_l3_d8, 3, 3, 1, relu=False, instance_norm=False)\n    output_l3 = tf.nn.tanh(conv_l3_out) * 0.58 + 0.5\n\n    # -------------------------------------------\n    # Processing: Level 2,  Input size: 128 x 128\n\n    conv_l2_d2 = stack(conv_l2_d1, conv_t2a)\n    conv_l2_d3 = stack(_conv_multi_block(conv_l2_d2, 5, num_maps=64, instance_norm=instance_norm), conv_l2_d1)\n\n    conv_l2_d4 = _conv_multi_block(conv_l2_d3, 7, num_maps=64, instance_norm=instance_norm) + conv_l2_d3\n    conv_l2_d5 = _conv_multi_block(conv_l2_d4, 7, num_maps=64, instance_norm=instance_norm) + conv_l2_d4\n    conv_l2_d6 = _conv_multi_block(conv_l2_d5, 7, num_maps=64, instance_norm=instance_norm) + conv_l2_d5\n    conv_l2_d7 = stack(_conv_multi_block(conv_l2_d6, 7, num_maps=64, instance_norm=instance_norm), conv_l2_d1)\n\n    conv_l2_d8 = stack(_conv_multi_block(conv_l2_d7, 5, num_maps=64, instance_norm=instance_norm), conv_t2b)\n    conv_l2_d9 = _conv_multi_block(conv_l2_d8, 3, num_maps=64, instance_norm=instance_norm)\n\n    conv_t1a = _conv_tranpose_layer(conv_l2_d9, 32, 3, 2)       # 128 -> 256\n    conv_t1b = _conv_tranpose_layer(conv_l2_d9, 32, 3, 2)       # 128 -> 256\n\n    # -> Output: Level 2\n\n    conv_l2_out = _conv_layer(conv_l2_d9, 3, 3, 1, relu=False, instance_norm=False)\n    output_l2 = tf.nn.tanh(conv_l2_out) * 0.58 + 0.5\n\n    # -------------------------------------------\n    # Processing: Level 1,  Input size: 256 x 256\n\n    conv_l1_d2 = stack(conv_l1_d1, conv_t1a)\n    conv_l1_d3 = stack(_conv_multi_block(conv_l1_d2, 5, num_maps=32, instance_norm=False), conv_l1_d1)\n\n    conv_l1_d4 = _conv_multi_block(conv_l1_d3, 7, num_maps=32, instance_norm=False)\n\n    conv_l1_d5 = _conv_multi_block(conv_l1_d4, 9, num_maps=32, instance_norm=instance_norm_level_1)\n    conv_l1_d6 = _conv_multi_block(conv_l1_d5, 9, num_maps=32, instance_norm=instance_norm_level_1) + conv_l1_d5\n    conv_l1_d7 = _conv_multi_block(conv_l1_d6, 9, num_maps=32, instance_norm=instance_norm_level_1) + conv_l1_d6\n    conv_l1_d8 = _conv_multi_block(conv_l1_d7, 9, num_maps=32, instance_norm=instance_norm_level_1) + conv_l1_d7\n\n    conv_l1_d9 = stack(_conv_multi_block(conv_l1_d8, 7, num_maps=32, instance_norm=False), conv_l1_d1)\n\n    conv_l1_d10 = stack(_conv_multi_block(conv_l1_d9, 5, num_maps=32, instance_norm=False), conv_t1b)\n    conv_l1_d11 = stack(conv_l1_d10, conv_l1_d1)\n\n    conv_l1_d12 = _conv_multi_block(conv_l1_d11, 3, num_maps=32, instance_norm=False)\n\n    # -> Output: Level 1\n\n    conv_l1_out = _conv_layer(conv_l1_d12, 3, 3, 1, relu=False, instance_norm=False)\n    output_l1 = tf.nn.tanh(conv_l1_out) * 0.58 + 0.5\n\n    # ----------------------------------------------------------\n    # Processing: Level 0 (x2 upscaling),  Input size: 256 x 256\n\n    conv_l0 = _conv_tranpose_layer(conv_l1_d12, 8, 3, 2)        # 256 -> 512\n    conv_l0_out = _conv_layer(conv_l0, 3, 3, 1, relu=False, instance_norm=False)\n    output_l0 = tf.nn.tanh(conv_l0_out) * 0.58 + 0.5\n\n    # ----------------------------------------------------------\n    # Processing: Level Up (x4 upscaling),  Input size: 512 x 512\n\n    conv_l_up = _conv_tranpose_layer(conv_l0_out, 3, 3, 2)  # 512 -> 1024\n    conv_l_up_out = _conv_layer(conv_l_up, 3, 3, 1, relu=False, instance_norm=False)\n\n    output_l_up = tf.nn.tanh(conv_l_up_out) * 0.58 + 0.5\n\n    return output_l_up\n","metadata":{"id":"ggz2P2HOvnlj","execution":{"iopub.status.busy":"2023-01-26T19:23:40.287055Z","iopub.execute_input":"2023-01-26T19:23:40.287654Z","iopub.status.idle":"2023-01-26T19:23:40.315285Z","shell.execute_reply.started":"2023-01-26T19:23:40.287616Z","shell.execute_reply":"2023-01-26T19:23:40.313975Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\ninput = tf.keras.Input(shape = (512, 512, 3, ))\nmodel  = tf.keras.Model(inputs = input, outputs = PyNET(input))","metadata":{"id":"P9Cs-vXnvnlk","execution":{"iopub.status.busy":"2023-01-26T19:23:40.316580Z","iopub.execute_input":"2023-01-26T19:23:40.316944Z","iopub.status.idle":"2023-01-26T19:23:43.131433Z","shell.execute_reply.started":"2023-01-26T19:23:40.316909Z","shell.execute_reply":"2023-01-26T19:23:43.130483Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Loading and Preprocessing Data","metadata":{"id":"nhRl0-kvvnlk"}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n# Autotune for fetching and parallel processing tasks\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"id":"vKgg_Mqvvnlk","execution":{"iopub.status.busy":"2023-01-26T19:23:43.132908Z","iopub.execute_input":"2023-01-26T19:23:43.133534Z","iopub.status.idle":"2023-01-26T19:23:43.139584Z","shell.execute_reply.started":"2023-01-26T19:23:43.133487Z","shell.execute_reply":"2023-01-26T19:23:43.138515Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"bokeh_dataset = tf.data.Dataset.list_files('/kaggle/input/bokehdataset/Training/small_bokeh/*.jpg', shuffle = False)\noriginal_dataset = tf.data.Dataset.list_files('/kaggle/input/bokehdataset/Training/small_orig/*.jpg', shuffle = False)\ndataset = tf.data.Dataset.zip((original_dataset, bokeh_dataset))\nimage_count = len(dataset)\nprint(f\"There are {image_count} original-bokeh image pairs in the dataset.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqz9ru2Jvnll","outputId":"d3d8d914-dc1b-446d-c51e-325da9ad0b90","execution":{"iopub.status.busy":"2023-01-26T19:23:43.141099Z","iopub.execute_input":"2023-01-26T19:23:43.141715Z","iopub.status.idle":"2023-01-26T19:23:43.537602Z","shell.execute_reply.started":"2023-01-26T19:23:43.141678Z","shell.execute_reply":"2023-01-26T19:23:43.536572Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"There are 1200 original-bokeh image pairs in the dataset.\n","output_type":"stream"}]},{"cell_type":"code","source":"def decode_img(img):\n    # Convert the compressed string to a 3D uint8 tensor\n    img = tf.io.decode_jpeg(img, channels=3)\n    # Resize the image to the desired size\n    img = tf.image.resize(img, [1024, 1536], method = 'bicubic')\n    return img\n\ndef process_path(original_path, bokeh_path):\n    # Load the raw data from the file as a string\n    bokeh_img = tf.io.read_file(bokeh_path)\n    original_img = tf.io.read_file(original_path)\n    bokeh_img = decode_img(bokeh_img)\n    original_img = decode_img(original_img)\n    return original_img, bokeh_img\n\n# Convert the dataset from filepaths to image tensors\ndataset = dataset.map(process_path, num_parallel_calls=AUTOTUNE)","metadata":{"id":"Wk7ZnXM7vnll","execution":{"iopub.status.busy":"2023-01-26T19:23:43.539176Z","iopub.execute_input":"2023-01-26T19:23:43.539727Z","iopub.status.idle":"2023-01-26T19:23:43.648653Z","shell.execute_reply.started":"2023-01-26T19:23:43.539689Z","shell.execute_reply":"2023-01-26T19:23:43.647639Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Splitting into training and validation datsets\ntrain_dataset = dataset.skip(int(image_count*0.2))\nvalidation_dataset = dataset.take(int(image_count*0.2))\n\nprint(f\"Training Dataset: {len(train_dataset)} image pairs\")\nprint(f\"Validation Dataset: {len(validation_dataset)} image pairs\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rh-7Sgi6vnll","outputId":"a209894f-86e4-44d8-dcb2-063233d8317a","execution":{"iopub.status.busy":"2023-01-26T19:23:43.651176Z","iopub.execute_input":"2023-01-26T19:23:43.651794Z","iopub.status.idle":"2023-01-26T19:23:43.659943Z","shell.execute_reply.started":"2023-01-26T19:23:43.651757Z","shell.execute_reply":"2023-01-26T19:23:43.658808Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Training Dataset: 960 image pairs\nValidation Dataset: 240 image pairs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We need random square crops of the image for input and output.","metadata":{"id":"ETliv_6Zvnll"}},{"cell_type":"code","source":"def random_crops(original, bokeh):\n    _, h, w, c = original.get_shape().as_list()\n    \"\"\"print(h, w)\n    print(batch.get_shape().as_list())\n    print(type(batch))\"\"\"\n    original = original/255.0\n    bokeh = bokeh/255.0\n    stacked = tf.concat((original, bokeh), axis = -1)\n    stacked = tf.image.random_crop(stacked, [BATCH_SIZE, 1024, 1024, 6])\n    original, bokeh = tf.split(stacked, num_or_size_splits=2, axis = -1)\n    original = tf.image.resize(original, size = [512, 512], method = 'bicubic')\n    return original, bokeh","metadata":{"id":"-3wKfEnuvnll","execution":{"iopub.status.busy":"2023-01-26T19:23:43.661535Z","iopub.execute_input":"2023-01-26T19:23:43.662107Z","iopub.status.idle":"2023-01-26T19:23:43.670306Z","shell.execute_reply.started":"2023-01-26T19:23:43.662042Z","shell.execute_reply":"2023-01-26T19:23:43.669210Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Resize and crop the dataset for training\ndef resize_for_training(train_dataset):\n    train_dataset = train_dataset.map(random_crops, num_parallel_calls=AUTOTUNE)\n    return train_dataset","metadata":{"id":"aT8i1KE8vnll","execution":{"iopub.status.busy":"2023-01-26T19:23:43.671810Z","iopub.execute_input":"2023-01-26T19:23:43.672883Z","iopub.status.idle":"2023-01-26T19:23:43.679118Z","shell.execute_reply.started":"2023-01-26T19:23:43.672848Z","shell.execute_reply":"2023-01-26T19:23:43.678100Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Improve performance of the data input pipeline\ndef configure_for_performance(dataset):\n#     dataset = dataset.shuffle(buffer_size=16)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(1)\n    return dataset","metadata":{"id":"QV_niD1svnlm","execution":{"iopub.status.busy":"2023-01-26T19:23:43.680412Z","iopub.execute_input":"2023-01-26T19:23:43.681188Z","iopub.status.idle":"2023-01-26T19:23:43.688712Z","shell.execute_reply.started":"2023-01-26T19:23:43.681127Z","shell.execute_reply":"2023-01-26T19:23:43.687726Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dataset = configure_for_performance(train_dataset)\nvalidation_dataset = configure_for_performance(validation_dataset)","metadata":{"id":"-niYpHvsvnlm","execution":{"iopub.status.busy":"2023-01-26T19:23:43.690141Z","iopub.execute_input":"2023-01-26T19:23:43.690551Z","iopub.status.idle":"2023-01-26T19:23:43.700564Z","shell.execute_reply.started":"2023-01-26T19:23:43.690478Z","shell.execute_reply":"2023-01-26T19:23:43.699545Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"type(train_dataset), len(train_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qu9RfiAU7zMQ","outputId":"d7b74cdd-5e2b-441a-88cc-023d644b6e3a","execution":{"iopub.status.busy":"2023-01-26T19:23:43.702219Z","iopub.execute_input":"2023-01-26T19:23:43.702614Z","iopub.status.idle":"2023-01-26T19:23:43.710346Z","shell.execute_reply.started":"2023-01-26T19:23:43.702570Z","shell.execute_reply":"2023-01-26T19:23:43.709266Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(tensorflow.python.data.ops.dataset_ops.PrefetchDataset, 240)"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = resize_for_training(train_dataset)","metadata":{"id":"N90witsOvnlm","execution":{"iopub.status.busy":"2023-01-26T19:23:43.712289Z","iopub.execute_input":"2023-01-26T19:23:43.712710Z","iopub.status.idle":"2023-01-26T19:23:43.806818Z","shell.execute_reply.started":"2023-01-26T19:23:43.712676Z","shell.execute_reply":"2023-01-26T19:23:43.805776Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"type(train_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbGQoyyn74dz","outputId":"75dba6da-58ab-4df8-ef47-ddf43c3a69c3","execution":{"iopub.status.busy":"2023-01-26T19:23:43.808702Z","iopub.execute_input":"2023-01-26T19:23:43.809070Z","iopub.status.idle":"2023-01-26T19:23:43.816887Z","shell.execute_reply.started":"2023-01-26T19:23:43.809034Z","shell.execute_reply":"2023-01-26T19:23:43.815832Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"tensorflow.python.data.ops.dataset_ops.ParallelMapDataset"},"metadata":{}}]},{"cell_type":"markdown","source":"# Custom Loss Function (For Level 1)","metadata":{"id":"Yx6eFiSrvnlm"}},{"cell_type":"markdown","source":"## VGG Network","metadata":{"id":"S5-YPsxOvnlm"}},{"cell_type":"code","source":"# !unzip '/content/drive/MyDrive/VGG.zip'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3-t_pFr2X35","outputId":"fe7c23cc-479e-4976-f340-62e084ec4279","execution":{"iopub.status.busy":"2023-01-26T19:23:43.818132Z","iopub.execute_input":"2023-01-26T19:23:43.819082Z","iopub.status.idle":"2023-01-26T19:23:43.824697Z","shell.execute_reply.started":"2023-01-26T19:23:43.819045Z","shell.execute_reply":"2023-01-26T19:23:43.823761Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from scipy.io import loadmat\nfrom tensorflow.keras.losses import MeanSquaredError\nvgg_matlab = loadmat('/kaggle/input/bokehdataset/VGG/VGG/imagenet-vgg-verydeep-19.mat')\nvgg_weights = vgg_matlab['layers'][0]\nlayers = (\n        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n\n        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n\n        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n\n        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n\n        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n        'relu5_3', 'conv5_4', 'relu5_4'\n    )","metadata":{"id":"EdAIb_Jtvnlm","execution":{"iopub.status.busy":"2023-01-26T19:23:43.825913Z","iopub.execute_input":"2023-01-26T19:23:43.827071Z","iopub.status.idle":"2023-01-26T19:23:44.307227Z","shell.execute_reply.started":"2023-01-26T19:23:43.827035Z","shell.execute_reply":"2023-01-26T19:23:44.306203Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"IMAGE_MEAN = np.array([123.68,  116.779,  103.939])\ndef vgg_conv_layer(input, weights, bias):\n    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1), padding='SAME')\n    return tf.nn.bias_add(conv, bias)\n\ndef vgg_net(input_image):\n    input_image = input_image - IMAGE_MEAN\n    current = input_image\n    net = current\n    for i, name in enumerate(layers):\n        layer_type = name[:4]\n        if layer_type == 'conv':\n            kernels, bias = vgg_weights[i][0][0][0][0]\n            kernels = np.transpose(kernels, (1, 0, 2, 3))\n            bias = bias.reshape(-1)\n            current = vgg_conv_layer(current, kernels, bias)\n        elif layer_type == 'relu':\n            current = tf.nn.relu(current)\n        elif layer_type == 'pool':\n            current = tf.nn.max_pool(current, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='SAME')\n        net = current\n\n    return net","metadata":{"id":"jLFRiPP5vnlm","execution":{"iopub.status.busy":"2023-01-26T19:23:44.308702Z","iopub.execute_input":"2023-01-26T19:23:44.309374Z","iopub.status.idle":"2023-01-26T19:23:44.320195Z","shell.execute_reply.started":"2023-01-26T19:23:44.309335Z","shell.execute_reply":"2023-01-26T19:23:44.318953Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def Level_1_loss(bokeh, target):\n    # L1_loss\n    # print(f\"shape of bokeh {bokeh.get_shape()}\")\n    # print(f\"shape of target {target.get_shape()}\")\n    l1_loss = tf.abs(tf.subtract(bokeh, target))\n    # SSIM loss\n    SSIM_loss = tf.reduce_mean(tf.image.ssim(bokeh, target, 1.0))\n    # VGG Loss\n    bokeh_image_vgg = vgg_net(bokeh*255)\n    target_vgg = vgg_net(target*255)\n    VGG_loss = MeanSquaredError()(bokeh_image_vgg, target_vgg)\n    return l1_loss + (1 - SSIM_loss) + 0.01*VGG_loss","metadata":{"id":"1Q9tXUWevnlm","execution":{"iopub.status.busy":"2023-01-26T19:23:44.322035Z","iopub.execute_input":"2023-01-26T19:23:44.322450Z","iopub.status.idle":"2023-01-26T19:23:44.330360Z","shell.execute_reply.started":"2023-01-26T19:23:44.322415Z","shell.execute_reply":"2023-01-26T19:23:44.329276Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Model Saving Checkpoints","metadata":{"id":"3aKKLNta22Xi"}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nsave_model = ModelCheckpoint(\n    '/kaggle/working/Model/pynet.h5',\n    save_best_only = True,\n    verbose = 1\n)","metadata":{"id":"Z4rNxyYd2x_a","execution":{"iopub.status.busy":"2023-01-26T19:55:18.005660Z","iopub.execute_input":"2023-01-26T19:55:18.006051Z","iopub.status.idle":"2023-01-26T19:55:18.011330Z","shell.execute_reply.started":"2023-01-26T19:55:18.006017Z","shell.execute_reply":"2023-01-26T19:55:18.010129Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nmodel.compile(\n    optimizer = Adam(1e-4),\n    loss = Level_1_loss,\n    metrics = ['MeanSquaredError']\n)","metadata":{"id":"UOFaAcsZvnlm","execution":{"iopub.status.busy":"2023-01-26T19:23:44.342618Z","iopub.execute_input":"2023-01-26T19:23:44.342981Z","iopub.status.idle":"2023-01-26T19:23:44.363666Z","shell.execute_reply.started":"2023-01-26T19:23:44.342948Z","shell.execute_reply":"2023-01-26T19:23:44.362859Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFa8iarN7WB0","outputId":"cce8069c-0c83-4d57-ac31-91c95f959e66","execution":{"iopub.status.busy":"2023-01-26T19:23:44.365137Z","iopub.execute_input":"2023-01-26T19:23:44.365496Z","iopub.status.idle":"2023-01-26T19:23:44.373063Z","shell.execute_reply.started":"2023-01-26T19:23:44.365463Z","shell.execute_reply":"2023-01-26T19:23:44.372041Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"240"},"metadata":{}}]},{"cell_type":"code","source":"# original, bokeh = next(iter(train_dataset))","metadata":{"id":"qsgLa5Zu6qUU","execution":{"iopub.status.busy":"2023-01-26T19:23:44.374724Z","iopub.execute_input":"2023-01-26T19:23:44.375528Z","iopub.status.idle":"2023-01-26T19:23:44.380468Z","shell.execute_reply.started":"2023-01-26T19:23:44.375488Z","shell.execute_reply":"2023-01-26T19:23:44.379400Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\"\"\"import matplotlib.pyplot as plt\nplt.figure(figsize=(10, 10))\nstart = 2\nfor i in range(start, start + 2):\n  ax = plt.subplot(2, 2, 2*(i-start) + 1)\n  plt.imshow(original[i].numpy().astype(\"uint8\"))\n  ax = plt.subplot(2, 2, 2*(i-start) + 2)\n  plt.imshow(bokeh[i].numpy().astype(\"uint8\"))\"\"\"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"id":"3oyy1c6D-CPp","outputId":"f757dd1a-19dc-45c5-ebd8-fe717d4acee2","execution":{"iopub.status.busy":"2023-01-26T19:23:44.382198Z","iopub.execute_input":"2023-01-26T19:23:44.382581Z","iopub.status.idle":"2023-01-26T19:23:44.390719Z","shell.execute_reply.started":"2023-01-26T19:23:44.382539Z","shell.execute_reply":"2023-01-26T19:23:44.389531Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'import matplotlib.pyplot as plt\\nplt.figure(figsize=(10, 10))\\nstart = 2\\nfor i in range(start, start + 2):\\n  ax = plt.subplot(2, 2, 2*(i-start) + 1)\\n  plt.imshow(original[i].numpy().astype(\"uint8\"))\\n  ax = plt.subplot(2, 2, 2*(i-start) + 2)\\n  plt.imshow(bokeh[i].numpy().astype(\"uint8\"))'"},"metadata":{}}]},{"cell_type":"code","source":"# config = tf.ConfigProto()\n# config.gpu_options.allow_growth = True\n# sess = tf.Session(config = config)\n# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n# tf.config.experimental.set_memory_growth(physical_devices[0], True)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:23:44.392481Z","iopub.execute_input":"2023-01-26T19:23:44.392984Z","iopub.status.idle":"2023-01-26T19:23:44.398887Z","shell.execute_reply.started":"2023-01-26T19:23:44.392950Z","shell.execute_reply":"2023-01-26T19:23:44.397807Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-01-26T20:10:14.862372Z","iopub.execute_input":"2023-01-26T20:10:14.862847Z","iopub.status.idle":"2023-01-26T20:10:15.919479Z","shell.execute_reply.started":"2023-01-26T20:10:14.862803Z","shell.execute_reply":"2023-01-26T20:10:15.918318Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_weights('kaggle/working/Model/pynet.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-26T20:08:46.323102Z","iopub.execute_input":"2023-01-26T20:08:46.324177Z","iopub.status.idle":"2023-01-26T20:08:46.374484Z","shell.execute_reply.started":"2023-01-26T20:08:46.324105Z","shell.execute_reply":"2023-01-26T20:08:46.373194Z"},"trusted":true},"execution_count":47,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_756/536096013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kaggle/working/Model/pynet.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[1;32m   2249\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2252\u001b[0m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to create file (unable to open file: name = 'kaggle/working/Model/pynet.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"],"ename":"FileNotFoundError","evalue":"[Errno 2] Unable to create file (unable to open file: name = 'kaggle/working/Model/pynet.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)","output_type":"error"}]},{"cell_type":"code","source":"model.fit(\n    train_dataset,\n    epochs = 1,\n    callbacks = [save_model]\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"ybhG2OM4vnln","outputId":"272360c0-d9e2-4a46-dcf3-e296f9d828ee","execution":{"iopub.status.busy":"2023-01-26T19:55:28.705050Z","iopub.execute_input":"2023-01-26T19:55:28.705453Z","iopub.status.idle":"2023-01-26T20:05:50.699718Z","shell.execute_reply.started":"2023-01-26T19:55:28.705422Z","shell.execute_reply":"2023-01-26T20:05:50.698574Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"240/240 [==============================] - 591s 2s/step - loss: 0.3796 - mean_squared_error: 0.0144\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fd0b971cf50>"},"metadata":{}}]}]}